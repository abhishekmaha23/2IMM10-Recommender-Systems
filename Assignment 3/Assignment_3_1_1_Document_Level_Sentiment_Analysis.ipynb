{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3MTWtWohZDkD"
   },
   "source": [
    "## Assignment 3.1. Sequence Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group 09\n",
    "\n",
    "Abhishek Mahadevan Raju (1306162), Priya Sivasubramanian (1378635), Natarajan Chidambaram (1358111)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tdQQfdrQZDkE"
   },
   "source": [
    "## Task 1.1: Document-level Sentiment Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H_lhmp5IZDkE"
   },
   "source": [
    "Build a Bidirectional Recurrent Neural Network (RNN) model for multi-class sentiment classification. Compare the performance with a Unidirectional RNN model. Your model (each) shall\n",
    "include:\n",
    "\n",
    "- RNN network that learns sentence representation from input sequences.\n",
    "- Fully connected network that predicts sentiment label, given the learnt state representation.\n",
    "\n",
    "\n",
    "Train the model by using data iterator and batch generator. Evaluate the trained model on\n",
    "the provided test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "13GNLSaWu7np"
   },
   "source": [
    "## Unidirectional RNN Model for document level sentiment classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FlYnGJLTZDkF",
    "outputId": "4c5c39fe-a860-439b-bb19-a9dce8557773"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20181592\\AppData\\Local\\Continuum\\anaconda3\\envs\\py3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import codecs\n",
    "import operator\n",
    "import numpy as np\n",
    "import re\n",
    "from time import time\n",
    "import _pickle as cPickle\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import operator\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding, LSTM, Input, Bidirectional\n",
    "from keras.models import Model\n",
    "import keras.optimizers as opt\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "kvvt_fUlb861",
    "outputId": "326dd0f1-5c0f-4da8-abf2-854f2302d30a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8hcGkWajb_aO",
    "outputId": "c1994786-2e89-4a93-98b6-6078a181d5f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/Colab Notebooks\n"
     ]
    }
   ],
   "source": [
    "cd drive/My Drive/Colab Notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g_vwhzseZDkO"
   },
   "outputs": [],
   "source": [
    "data_path = 'data/doc_level'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AamP9B4dZDkQ"
   },
   "outputs": [],
   "source": [
    "num_regex = re.compile('^[+-]?[0-9]+\\.?[0-9]*$')\n",
    "\n",
    "def create_vocab(domain, data_path, maxlen=0, vocab_size=0):\n",
    "    \n",
    "    print('Creating vocab ...')\n",
    "\n",
    "    f = os.path.join(data_path,'%s_text.txt'%(domain))\n",
    "\n",
    "    total_words, unique_words = 0, 0\n",
    "    word_freqs = {}\n",
    "\n",
    "    fin = codecs.open(f, 'r', 'utf-8')\n",
    "    for line in fin:\n",
    "        words = line.split()\n",
    "        if maxlen > 0 and len(words) > maxlen:\n",
    "            continue\n",
    "\n",
    "        for w in words:\n",
    "            if not bool(num_regex.match(w)):\n",
    "                try:\n",
    "                    word_freqs[w] += 1\n",
    "                except KeyError:\n",
    "                    unique_words += 1\n",
    "                    word_freqs[w] = 1\n",
    "                total_words += 1\n",
    "\n",
    "    print ('  %i total words, %i unique words' % (total_words, unique_words))\n",
    "    sorted_word_freqs = sorted(word_freqs.items(), key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "    vocab = {'<pad>':0, '<unk>':1, '<num>':2}\n",
    "    index = len(vocab)\n",
    "    for word, _ in sorted_word_freqs:\n",
    "        vocab[word] = index\n",
    "        index += 1\n",
    "        if vocab_size > 0 and index > vocab_size + 2:\n",
    "            break\n",
    "    if vocab_size > 0:\n",
    "        print (' keep the top %i words' % vocab_size)\n",
    "\n",
    "  \n",
    "    return vocab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G0KWSIFwZDkS"
   },
   "outputs": [],
   "source": [
    "def create_data(vocab, text_path, label_path, domain, skip_top, skip_len, replace_non_vocab):\n",
    "    \n",
    "    data = []\n",
    "    label = [] # {pos: 0, neg: 1, neu: 2}\n",
    "    \n",
    "    f = codecs.open(text_path, 'r', 'utf-8')\n",
    "    f_l = codecs.open(label_path, 'r', 'utf-8')\n",
    "    \n",
    "    num_hit, unk_hit, skip_top_hit, total = 0., 0., 0., 0.\n",
    "    pos_count, neg_count, neu_count = 0, 0, 0\n",
    "    max_len = 0\n",
    "\n",
    "    for line, score in zip(f, f_l):\n",
    "        word_indices = []\n",
    "        words = line.split()\n",
    "        if skip_len > 0 and len(words) > skip_len:\n",
    "            continue\n",
    "\n",
    "        score = float(score.strip())\n",
    "        if score < 3:\n",
    "            neg_count += 1\n",
    "            label.append(1)\n",
    "        elif score > 3:\n",
    "            pos_count += 1\n",
    "            label.append(0)\n",
    "        else:\n",
    "            neu_count += 1\n",
    "            label.append(2)\n",
    "          \n",
    "        for word in words:\n",
    "            if bool(num_regex.match(word)):\n",
    "                word_indices.append(vocab['<num>'])\n",
    "                num_hit += 1\n",
    "            elif word in vocab:\n",
    "                word_ind = vocab[word]\n",
    "                if skip_top > 0 and word_ind < skip_top + 3:\n",
    "                    skip_top_hit += 1\n",
    "                else:\n",
    "                    word_indices.append(word_ind)\n",
    "            else:\n",
    "                if replace_non_vocab:\n",
    "                    word_indices.append(vocab['<unk>'])\n",
    "                unk_hit += 1\n",
    "            total += 1\n",
    "\n",
    "        if len(word_indices) > max_len:\n",
    "            max_len = len(word_indices)\n",
    "\n",
    "        data.append(word_indices)\n",
    "\n",
    "    f.close()\n",
    "    f_l.close()\n",
    "\n",
    "    print('  <num> hit rate: %.2f%%, <unk> hit rate: %.2f%%' % (100*num_hit/total, 100*unk_hit/total))\n",
    "\n",
    "    print (domain)\n",
    "    print( 'pos count: ', pos_count )\n",
    "    print( 'neg count: ', neg_count )\n",
    "    print( 'neu count: ', neu_count )\n",
    "\n",
    "    return np.array(data), np.array(label), max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zAIC_dGJZDkU"
   },
   "outputs": [],
   "source": [
    "def prepare_data(domain, data_path, vocab_size, skip_top=0, skip_len=0, replace_non_vocab=1):\n",
    "    \n",
    "    print(domain)\n",
    "\n",
    "    assert domain in ['amazon_electronics', 'yelp14']\n",
    "\n",
    "    vocab = create_vocab(domain, data_path, skip_len, vocab_size)\n",
    "    #print(vocab)\n",
    "\n",
    "    text_path = os.path.join(data_path,'%s_text.txt'%(domain))\n",
    "    score_path = os.path.join(data_path,'%s_label.txt'%(domain))\n",
    "\n",
    "    data, label, max_len = create_data(vocab, text_path, score_path, domain, skip_top, \\\n",
    "                                       skip_len, replace_non_vocab)\n",
    "\n",
    "    return vocab, data, label, max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WbsM4S_hZDkW"
   },
   "outputs": [],
   "source": [
    "# choose domain data to train\n",
    "domain_name = 'amazon_electronics'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 168
    },
    "colab_type": "code",
    "id": "4D0wK6OSZDkZ",
    "outputId": "1453844b-262e-434a-9c29-dfd21386be0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amazon_electronics\n",
      "Creating vocab ...\n",
      "  3440972 total words, 39122 unique words\n",
      " keep the top 10000 words\n",
      "  <num> hit rate: 1.04%, <unk> hit rate: 1.56%\n",
      "amazon_electronics\n",
      "pos count:  10000\n",
      "neg count:  10000\n",
      "neu count:  10000\n"
     ]
    }
   ],
   "source": [
    "vocab, data_list, label_list, overall_maxlen = prepare_data(domain_name, data_path, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MFto63C6ZDkb"
   },
   "outputs": [],
   "source": [
    "idx_words = dict((v,k) for (k,v) in vocab.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k-ah9J-JZDkf"
   },
   "outputs": [],
   "source": [
    "data_path_save = 'Assign3DataStorage/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1sSWysVPZDkh"
   },
   "outputs": [],
   "source": [
    "def read_pickle(path_data, file_name):\n",
    "\n",
    "    f = open(os.path.join(path_data, file_name), 'rb')\n",
    "    read_file = cPickle.load(f)\n",
    "    f.close()\n",
    "\n",
    "    return read_file\n",
    "\n",
    "def save_pickle(path_data, file_name, data):\n",
    "\n",
    "    f = open(os.path.join(path_data, file_name), 'wb')\n",
    "    cPickle.dump(data, f)\n",
    "    print(\" file saved to: %s\"%(os.path.join(path_data, file_name)))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "eYzedUW0ZDkk",
    "outputId": "602e1194-f32d-42de-81fd-4c9260ae98ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " file saved to: Assign3DataStorage/words_idx.pkl\n"
     ]
    }
   ],
   "source": [
    "save_pickle(data_path_save, 'words_idx.pkl', vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Yc69Zb44ZDkm",
    "outputId": "d196f53d-ffa3-4eee-c852-855456130de9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " file saved to: Assign3DataStorage/idx_words.pkl\n"
     ]
    }
   ],
   "source": [
    "save_pickle(data_path_save, 'idx_words.pkl', idx_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "KRmIZeleZDko",
    "outputId": "c6f9647b-3365-4ef9-d286-dcaea06e8567"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " file saved to: Assign3DataStorage/data.pkl\n"
     ]
    }
   ],
   "source": [
    "save_pickle(data_path_save, 'data.pkl', data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "eDkScGLEZDkq",
    "outputId": "0c861365-7b7f-4a8f-98b6-59e35135e9fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " file saved to: Assign3DataStorage/label.pkl\n"
     ]
    }
   ],
   "source": [
    "save_pickle(data_path_save, 'label.pkl', label_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "322613UpZDks"
   },
   "source": [
    "### End of Preprocessing\n",
    "\n",
    "### Model training, testing and conclusion summary of these are as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KTi7HvMaZDkv"
   },
   "outputs": [],
   "source": [
    "words_idx = read_pickle(data_path, 'words_idx.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z7o1JLnPZDky"
   },
   "outputs": [],
   "source": [
    "idx_words = read_pickle(data_path, 'idx_words.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8G5-kFUxZDk2"
   },
   "outputs": [],
   "source": [
    "data = read_pickle(data_path, 'data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M9B9BHH2ZDk5"
   },
   "outputs": [],
   "source": [
    "label = read_pickle(data_path, 'label.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0WrFfdvYZDk7"
   },
   "outputs": [],
   "source": [
    "rand_idx = np.arange(len(data))\n",
    "np.random.shuffle(rand_idx)\n",
    "\n",
    "data = data[rand_idx]\n",
    "label = to_categorical(label)[rand_idx]\n",
    "\n",
    "data_size = len(data)\n",
    "\n",
    "test_x = data[0:6000]\n",
    "test_y = label[0:6000]\n",
    "\n",
    "dev_x = data[6000:10800]\n",
    "dev_y = label[6000:10800]\n",
    "\n",
    "train_x = data[10800:int(data_size)]\n",
    "train_y = label[10800:int(data_size)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-pnMCOOPZDk9"
   },
   "outputs": [],
   "source": [
    "maxlen = 300\n",
    "words_idx = [x for (x, _) in sorted(words_idx.items(), key=operator.itemgetter(1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cOa6UpLnZDlA"
   },
   "outputs": [],
   "source": [
    "train_x_ = sequence.pad_sequences(train_x, maxlen)\n",
    "dev_x_ = sequence.pad_sequences(dev_x, maxlen)\n",
    "test_x_ = sequence.pad_sequences(test_x, maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aZfs4bfKZDlC"
   },
   "outputs": [],
   "source": [
    "train_x_ = np.array(train_x_)\n",
    "train_y = np.array(train_y)\n",
    "\n",
    "dev_x_ = np.array(dev_x_)\n",
    "dev_y = np.array(dev_y)\n",
    "\n",
    "test_x_ = np.array(test_x_)\n",
    "test_y = np.array(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OsMZENHJZDlE"
   },
   "outputs": [],
   "source": [
    "class Dataiterator():\n",
    "    '''\n",
    "      1) Iteration over minibatches using next(); call reset() between epochs to randomly shuffle the data\n",
    "      2) Access to the entire dataset using all()\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, X, y, seq_length=32, decoder_dim=300, batch_size=32):      \n",
    "        self.X = X \n",
    "        self.y = y \n",
    "        self.num_data = len(X) # total number of examples\n",
    "        self.batch_size = batch_size # batch size\n",
    "        self.reset() # initial: shuffling examples and set index to 0\n",
    "    \n",
    "    def __iter__(self): # iterates data\n",
    "        return self\n",
    "\n",
    "\n",
    "    def reset(self): # initials\n",
    "        self.idx = 0\n",
    "        self.order = np.random.permutation(self.num_data) # shuffling examples by providing randomized ids \n",
    "        \n",
    "    def __next__(self): # return model inputs - outputs per batch\n",
    "        X_ids = [] # hold ids per batch \n",
    "        while len(X_ids) < self.batch_size:\n",
    "            X_id = self.order[self.idx] # copy random id from initial shuffling\n",
    "            X_ids.append(X_id)\n",
    "            self.idx += 1 # \n",
    "            if self.idx >= self.num_data: # exception if all examples of data have been seen (iterated)\n",
    "                self.reset()\n",
    "                raise StopIteration()\n",
    "        batch_X = self.X[np.array(X_ids)] # X values (encoder input) per batch\n",
    "        batch_y = self.y[np.array(X_ids)] # y_in values (decoder input) per batch\n",
    "        return batch_X, batch_y\n",
    "\n",
    "          \n",
    "    def all(self): # return all data examples\n",
    "        return self.X, self.y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eGNvIJq27wu2"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZE6J0oSXZDlH"
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "sentence_input = Input(shape=(300,), dtype='int32', name='sentence_input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 138
    },
    "colab_type": "code",
    "id": "5pO9OyJEZDlJ",
    "outputId": "a0ddc9cf-1763-4370-e743-040459add59e"
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "vocab_size = len(words_idx)\n",
    "word_emb = Embedding(vocab_size, 300, mask_zero=True, name='word_emb')\n",
    "emb_output = word_emb(sentence_input)\n",
    "drop = Dropout(0.25)(emb_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ci_lCnzGZDlL"
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "# 1 no embd drop, lstm dropout = 0.5, reccr drop = 0.1\n",
    "dropout6 = 0.5\n",
    "recurrent_dropout6 = 0.1\n",
    "lstm_layer6 = LSTM(300, return_sequences=False, dropout=dropout6, \\\n",
    "              recurrent_dropout=recurrent_dropout6, name='lstm6')(emb_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tv4noVsU1Vsh"
   },
   "outputs": [],
   "source": [
    "# 2 embd drop = 0.25, lstm dropout = 0.5, reccr drop = 0.1\n",
    "dropout4 = 0.5\n",
    "recurrent_dropout4 = 0.1\n",
    "lstm_layer4 = LSTM(300, return_sequences=False, dropout=dropout4, \\\n",
    "              recurrent_dropout=recurrent_dropout4, name='lstm4')(drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "anCOg4An1Vx4"
   },
   "outputs": [],
   "source": [
    "# 3 embd drop = 0.25, lstm dropout = 0.5, reccr drop = 0.2\n",
    "dropout5 = 0.5\n",
    "recurrent_dropout5 = 0.2\n",
    "lstm_layer5 = LSTM(300, return_sequences=False, dropout=dropout5, \\\n",
    "              recurrent_dropout=recurrent_dropout5, name='lstm5')(drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9MZVztISZDlO"
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "densed6 = Dense(3, name='dense')(lstm_layer6)\n",
    "probs6 = Activation('softmax')(densed6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ULRa_eRk4lzO"
   },
   "outputs": [],
   "source": [
    "densed4 = Dense(3, name='dense')(lstm_layer4)\n",
    "probs4 = Activation('softmax')(densed4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LRp3c0uI4l31"
   },
   "outputs": [],
   "source": [
    "densed5 = Dense(3, name='dense')(lstm_layer5)\n",
    "probs5 = Activation('softmax')(densed5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NfJt5RDkZDlS"
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "model6 = Model(inputs=[sentence_input], outputs=probs6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wsfseUbi4x1Y"
   },
   "outputs": [],
   "source": [
    "model4 = Model(inputs=[sentence_input], outputs=probs4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TsHrtvKo4x5u"
   },
   "outputs": [],
   "source": [
    "model5 = Model(inputs=[sentence_input], outputs=probs5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KPUJfQB945ma"
   },
   "outputs": [],
   "source": [
    "optimizer = opt.RMSprop(lr=0.001, rho=0.9, epsilon=1e-06, clipnorm=10, clipvalue=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "colab_type": "code",
    "id": "cIz2Yr5iZDlT",
    "outputId": "f99146a6-0b2f-4663-dd21-c345fa48742e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sentence_input (InputLayer)  (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "word_emb (Embedding)         (None, 300, 300)          3000900   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 300, 300)          0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 300)               721200    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3)                 903       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 3,723,003\n",
      "Trainable params: 3,723,003\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model6.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print(\"summary of Model6\")\n",
    "model6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_eVQlsEX49EI"
   },
   "outputs": [],
   "source": [
    "model4.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print(\"summary of Model4\")\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XHjkY3pP49A-"
   },
   "outputs": [],
   "source": [
    "model5.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print(\"summary of Model5\")\n",
    "model5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nyjqhu5WZDlW"
   },
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ytCdoIMZLMdF",
    "outputId": "cb153ce3-b573-4cb2-f6e0-a9e3bdaee478"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SLJce3JMZDlX"
   },
   "outputs": [],
   "source": [
    "train_steps_epoch = len(train_x_)/batch_size\n",
    "batch_train_iter = Dataiterator(train_x_, train_y, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fzEpDbA0ZDlZ"
   },
   "outputs": [],
   "source": [
    "val_steps_epoch = len(dev_x_)/batch_size\n",
    "batch_val_iter = Dataiterator(dev_x_, dev_y, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J1LOk0TZZDla"
   },
   "outputs": [],
   "source": [
    "test_steps_epoch = len(test_x_)/batch_size\n",
    "batch_test_iter = Dataiterator(test_x_, test_y, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6hr7hwNZZDlc"
   },
   "outputs": [],
   "source": [
    "def train_generator(model, batch_train_iter, batch_val_iter):\n",
    "    earlystop_callbacks = [EarlyStopping(monitor='val_loss', patience=12),\n",
    "                     ModelCheckpoint(filepath=os.path.join('./','{epoch:02d}-{loss:.2f}.check'), \\\n",
    "                                     monitor='val_loss', save_best_only=False, \\\n",
    "                                     save_weights_only=True)\n",
    "                     ]\n",
    "\n",
    "    def train_gen():\n",
    "        while True:\n",
    "            train_batches = [[X, y] for X, y in batch_train_iter]\n",
    "            for train_batch in train_batches:\n",
    "                yield train_batch\n",
    "\n",
    "    def val_gen():\n",
    "        while True:\n",
    "            val_batches = [[X, y] for X, y in batch_val_iter]\n",
    "            for val_batch in val_batches:\n",
    "                yield val_batch\n",
    "\n",
    "    history = model.fit_generator(train_gen(), validation_data=val_gen(), \\\n",
    "                                  validation_steps=val_steps_epoch, steps_per_epoch=train_steps_epoch, \\\n",
    "                                  epochs = 20, callbacks = earlystop_callbacks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rCsq1fyt9RFC"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 655
    },
    "colab_type": "code",
    "id": "NVYpk1MyZDle",
    "outputId": "9598bd59-9858-4883-fc4a-0472e876e0d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "600/600 [==============================] - 440s 733ms/step - loss: 0.9275 - categorical_accuracy: 0.5528 - val_loss: 0.8156 - val_categorical_accuracy: 0.6204\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 433s 722ms/step - loss: 0.7730 - categorical_accuracy: 0.6562 - val_loss: 0.7854 - val_categorical_accuracy: 0.6360\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 432s 720ms/step - loss: 0.7033 - categorical_accuracy: 0.6928 - val_loss: 0.8685 - val_categorical_accuracy: 0.5979\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 436s 727ms/step - loss: 0.6401 - categorical_accuracy: 0.7302 - val_loss: 0.7833 - val_categorical_accuracy: 0.6458\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 433s 722ms/step - loss: 0.5846 - categorical_accuracy: 0.7596 - val_loss: 0.8080 - val_categorical_accuracy: 0.6475\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 433s 722ms/step - loss: 0.5304 - categorical_accuracy: 0.7837 - val_loss: 0.9257 - val_categorical_accuracy: 0.6448\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 433s 721ms/step - loss: 0.4852 - categorical_accuracy: 0.8096 - val_loss: 0.8485 - val_categorical_accuracy: 0.6596\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 432s 720ms/step - loss: 0.4355 - categorical_accuracy: 0.8301 - val_loss: 0.8774 - val_categorical_accuracy: 0.6519\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 432s 720ms/step - loss: 0.3870 - categorical_accuracy: 0.8530 - val_loss: 0.9241 - val_categorical_accuracy: 0.6356\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 431s 719ms/step - loss: 0.3436 - categorical_accuracy: 0.8698 - val_loss: 0.9710 - val_categorical_accuracy: 0.6375\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 433s 721ms/step - loss: 0.2976 - categorical_accuracy: 0.8878 - val_loss: 1.0683 - val_categorical_accuracy: 0.6365\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 434s 723ms/step - loss: 0.2505 - categorical_accuracy: 0.9097 - val_loss: 1.2275 - val_categorical_accuracy: 0.6315\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 437s 728ms/step - loss: 0.2252 - categorical_accuracy: 0.9178 - val_loss: 1.2992 - val_categorical_accuracy: 0.6202\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 435s 725ms/step - loss: 0.1856 - categorical_accuracy: 0.9335 - val_loss: 1.3622 - val_categorical_accuracy: 0.6265\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 433s 722ms/step - loss: 0.1616 - categorical_accuracy: 0.9439 - val_loss: 1.4154 - val_categorical_accuracy: 0.6231\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 432s 720ms/step - loss: 0.1314 - categorical_accuracy: 0.9532 - val_loss: 1.5199 - val_categorical_accuracy: 0.6281\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 432s 721ms/step - loss: 0.1070 - categorical_accuracy: 0.9630 - val_loss: 1.7851 - val_categorical_accuracy: 0.6302\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 430s 716ms/step - loss: 0.0938 - categorical_accuracy: 0.9674 - val_loss: 1.8741 - val_categorical_accuracy: 0.6235\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 431s 719ms/step - loss: 0.0756 - categorical_accuracy: 0.9746 - val_loss: 2.0088 - val_categorical_accuracy: 0.6040\n"
     ]
    }
   ],
   "source": [
    "#Input shape as (300, )\n",
    "print(\"Training for model6\")\n",
    "train_generator(model3, batch_train_iter, batch_val_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zoL4wDwO5NOq"
   },
   "outputs": [],
   "source": [
    "print(\"Training for model4\")\n",
    "train_generator(model4, batch_train_iter, batch_val_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mK2WBcnL5NSP"
   },
   "outputs": [],
   "source": [
    "print(\"Training for model5\")\n",
    "train_generator(model5, batch_train_iter, batch_val_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P0nLb2Ki9wzR"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "wi8iSvAVZDlh",
    "outputId": "821e197c-e288-480c-cb13-9c5b9a9e4020"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 42s 7ms/step\n",
      "1.0987549308141074\n",
      "0.33866666666666667\n"
     ]
    }
   ],
   "source": [
    "#Input shape as (300, )\n",
    "print(\"Testing for model6\")\n",
    "loss, accuracy = model3.evaluate(x = test_x_, y = test_y, verbose = 1)\n",
    "\n",
    "print(loss)\n",
    "print(accuracy) #was 63.33, re-execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NrxcxzNR5TZ1"
   },
   "outputs": [],
   "source": [
    "print(\"Testing for model4\")\n",
    "loss, accuracy = model4.evaluate(x = test_x_, y = test_y, verbose = 1)\n",
    "\n",
    "print(loss)\n",
    "print(accuracy) #was 63.33, re-execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K5C_IiXb5Te4"
   },
   "outputs": [],
   "source": [
    "print(\"Testing for model5\")\n",
    "loss, accuracy = model5.evaluate(x = test_x_, y = test_y, verbose = 1)\n",
    "\n",
    "print(loss)\n",
    "print(accuracy) #was 63.33, re-execute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p__h3JT8ZDlt"
   },
   "source": [
    "## Bidirectional RNN Model for document level sentiment classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bw1HNQnXZDlu"
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "sentence_input = Input(shape = (maxlen, ), dtype = 'int32', name = 'sentence_input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lCqblVR6_Jrx"
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "vocab_size = len(words_idx)\n",
    "word_emb = Embedding(vocab_size, maxlen, mask_zero=True, name='word_emb')\n",
    "emb_output = word_emb(sentence_input)\n",
    "drop = Dropout(0.25)(emb_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fcTTmZRf_Jvg"
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "# 1 no embd drop, lstmdrop = 0.5, recdrop = 0.1\n",
    "dropout1 = 0.5\n",
    "recurrent_dropout1 = 0.1\n",
    "lstm_layer1 = Bidirectional(LSTM(maxlen, return_sequences=False, dropout=dropout1, \\\n",
    "              recurrent_dropout=recurrent_dropout1, name='lstm1'))(emb_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZStz9Vrh_JpT"
   },
   "outputs": [],
   "source": [
    "# 2 embd drop = 0.25, lstmdrop = 0.5, recdrop = 0.1\n",
    "dropout2 = 0.5\n",
    "recurrent_dropout2 = 0.1\n",
    "lstm_layer2 = Bidirectional(LSTM(maxlen, return_sequences=False, dropout=dropout2, \\\n",
    "              recurrent_dropout=recurrent_dropout2, name='lstm2'))(drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R8nuZCbG_TMn"
   },
   "outputs": [],
   "source": [
    "# 3 embd drop = 0.25, lstmdrop = 0.5, recdrop = 0.2\n",
    "dropout3 = 0.5\n",
    "recurrent_dropout3 = 0.2\n",
    "lstm_layer3 = Bidirectional(LSTM(maxlen, return_sequences=False, dropout=dropout3, \\\n",
    "              recurrent_dropout=recurrent_dropout3, name='lstm3'))(drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7 embd drop = 0.25, lstmdrop = 0.5, recdrop = 0.2, merge_mode = 'ave'\n",
    "dropout7 = 0.5\n",
    "recurrent_dropout7 = 0.2\n",
    "lstm_layer7 = Bidirectional(LSTM(maxlen, return_sequences=False, dropout=dropout7, \\\n",
    "              recurrent_dropout=recurrent_dropout7, name='lstm3'), merge_mode = 'ave')(drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rtB15cMcaPWb"
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "densed1 = Dense(3, name='dense1')(lstm_layer1)\n",
    "probs1 = Activation('softmax')(densed1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i4SFGQbQhtP8"
   },
   "outputs": [],
   "source": [
    "densed2 = Dense(3, name='dense2')(lstm_layer2)\n",
    "probs2 = Activation('softmax')(densed2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zDzCqccGhtTk"
   },
   "outputs": [],
   "source": [
    "densed3 = Dense(3, name='dense3')(lstm_layer3)\n",
    "probs3 = Activation('softmax')(densed3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "densed7 = Dense(3, name='dense3')(lstm_layer7)\n",
    "probs7 = Activation('softmax')(densed7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rSH0BdPAaPWd"
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "model1 = Model(inputs=[sentence_input], outputs=probs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OL_QxtmGh4rG"
   },
   "outputs": [],
   "source": [
    "model2 = Model(inputs=[sentence_input], outputs=probs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wdyPd268h4v5"
   },
   "outputs": [],
   "source": [
    "model3 = Model(inputs=[sentence_input], outputs=probs3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model7 = Model(inputs=[sentence_input], outputs=probs7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8OOGbJE4sfbw"
   },
   "outputs": [],
   "source": [
    "optimizer = opt.RMSprop(lr=0.001, rho=0.9, epsilon=1e-06, clipnorm=10, clipvalue=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "colab_type": "code",
    "id": "_zb_sFGZaPWf",
    "outputId": "cec0c90b-9f0c-4f16-c8ca-a1b58eff6edd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sentence_input (InputLayer)  (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "word_emb (Embedding)         (None, 300, 300)          3000900   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 300, 300)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 600)               1442400   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3)                 1803      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 4,445,103\n",
      "Trainable params: 4,445,103\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print(\"The summary for Model1\")\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8n1XXXWfiC1n"
   },
   "outputs": [],
   "source": [
    "model2.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print(\"The summary for Model2\")\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cyiqh4JwiC7N"
   },
   "outputs": [],
   "source": [
    "model3.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print(\"The summary for Model3\")\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The summary for Model7\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sentence_input (InputLayer)  (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "word_emb (Embedding)         (None, 300, 300)          3000900   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 300, 300)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 300)               1442400   \n",
      "_________________________________________________________________\n",
      "dense3 (Dense)               (None, 3)                 903       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 4,444,203\n",
      "Trainable params: 4,444,203\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model7.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print(\"The summary for Model7\")\n",
    "model7.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "peyjAqdkaPWi"
   },
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "djtKTVp0aPWl"
   },
   "outputs": [],
   "source": [
    "train_steps_epoch = len(train_x_)/batch_size\n",
    "batch_train_iter = Dataiterator(train_x_, train_y, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3gPBVT0yaPWn"
   },
   "outputs": [],
   "source": [
    "val_steps_epoch = len(dev_x_)/batch_size\n",
    "batch_val_iter = Dataiterator(dev_x_, dev_y, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iuluXwQyaPWp"
   },
   "outputs": [],
   "source": [
    "test_steps_epoch = len(test_x_)/batch_size\n",
    "batch_test_iter = Dataiterator(test_x_, test_y, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ov35iCM7aPWs"
   },
   "outputs": [],
   "source": [
    "def train_generator(model, batch_train_iter, batch_val_iter):\n",
    "    earlystop_callbacks = [EarlyStopping(monitor='val_loss', patience=10),\n",
    "                     ModelCheckpoint(filepath=os.path.join('./','{epoch:02d}-{loss:.2f}.check'), \\\n",
    "                                     monitor='val_loss', save_best_only=False, \\\n",
    "                                     save_weights_only=True)\n",
    "                     ]\n",
    "\n",
    "    def train_gen():\n",
    "        while True:\n",
    "            train_batches = [[X, y] for X, y in batch_train_iter]\n",
    "            for train_batch in train_batches:\n",
    "                yield train_batch\n",
    "\n",
    "    def val_gen():\n",
    "        while True:\n",
    "            val_batches = [[X, y] for X, y in batch_val_iter]\n",
    "            for val_batch in val_batches:\n",
    "                yield val_batch\n",
    "\n",
    "    history = model.fit_generator(train_gen(), validation_data=val_gen(), \\\n",
    "                                  validation_steps=val_steps_epoch, steps_per_epoch=train_steps_epoch, \\\n",
    "                                  epochs = 20, callbacks = earlystop_callbacks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 490
    },
    "colab_type": "code",
    "id": "_Q6VsVofaPWu",
    "outputId": "a527abbb-b87d-4b3f-a46d-18f05ffbd924"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1331s 2s/step - loss: 0.8923 - categorical_accuracy: 0.5780 - val_loss: 0.7570 - val_categorical_accuracy: 0.6621\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 1320s 2s/step - loss: 0.7168 - categorical_accuracy: 0.6852 - val_loss: 0.7202 - val_categorical_accuracy: 0.6737\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 1320s 2s/step - loss: 0.6425 - categorical_accuracy: 0.7255 - val_loss: 0.7411 - val_categorical_accuracy: 0.6615\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 1322s 2s/step - loss: 0.5686 - categorical_accuracy: 0.7628 - val_loss: 0.7206 - val_categorical_accuracy: 0.6817\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 1352s 2s/step - loss: 0.5077 - categorical_accuracy: 0.7946 - val_loss: 0.8369 - val_categorical_accuracy: 0.6725\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 1356s 2s/step - loss: 0.4487 - categorical_accuracy: 0.8234 - val_loss: 0.8080 - val_categorical_accuracy: 0.6706\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 1365s 2s/step - loss: 0.3935 - categorical_accuracy: 0.8460 - val_loss: 0.8641 - val_categorical_accuracy: 0.6677\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 1356s 2s/step - loss: 0.3378 - categorical_accuracy: 0.8699 - val_loss: 0.9594 - val_categorical_accuracy: 0.6656\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 1351s 2s/step - loss: 0.2860 - categorical_accuracy: 0.8941 - val_loss: 0.9772 - val_categorical_accuracy: 0.6608\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 1255s 2s/step - loss: 0.2379 - categorical_accuracy: 0.9133 - val_loss: 1.0586 - val_categorical_accuracy: 0.6548\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 895s 1s/step - loss: 0.1892 - categorical_accuracy: 0.9303 - val_loss: 1.2131 - val_categorical_accuracy: 0.6383\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 893s 1s/step - loss: 0.1511 - categorical_accuracy: 0.9446 - val_loss: 1.3698 - val_categorical_accuracy: 0.6390\n"
     ]
    }
   ],
   "source": [
    "#Without drop 0.25\n",
    "print(\"TRAINING FOR MODEL1\")\n",
    "train_generator(model1, batch_train_iter, batch_val_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iMYm2hFqiUfu"
   },
   "outputs": [],
   "source": [
    "print(\"TRAINING FOR MODEL2\")\n",
    "train_generator(model2, batch_train_iter, batch_val_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oHhaNdgSiUsA"
   },
   "outputs": [],
   "source": [
    "print(\"TRAINING FOR MODEL3\")\n",
    "train_generator(model3, batch_train_iter, batch_val_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING FOR MODEL3\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 783s 1s/step - loss: 0.9205 - categorical_accuracy: 0.5572 - val_loss: 0.8036 - val_categorical_accuracy: 0.6181\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 783s 1s/step - loss: 0.7501 - categorical_accuracy: 0.6650 - val_loss: 0.7679 - val_categorical_accuracy: 0.6400\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 797s 1s/step - loss: 0.6825 - categorical_accuracy: 0.7056 - val_loss: 0.7427 - val_categorical_accuracy: 0.6698\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 786s 1s/step - loss: 0.6252 - categorical_accuracy: 0.7358 - val_loss: 0.7199 - val_categorical_accuracy: 0.6687\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 786s 1s/step - loss: 0.5811 - categorical_accuracy: 0.7544 - val_loss: 0.7424 - val_categorical_accuracy: 0.6660\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 961s 2s/step - loss: 0.5289 - categorical_accuracy: 0.7839 - val_loss: 0.7496 - val_categorical_accuracy: 0.6769\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 799s 1s/step - loss: 0.4829 - categorical_accuracy: 0.8093 - val_loss: 0.7860 - val_categorical_accuracy: 0.6746\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 785s 1s/step - loss: 0.4396 - categorical_accuracy: 0.8269 - val_loss: 0.8218 - val_categorical_accuracy: 0.6660\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 790s 1s/step - loss: 0.3963 - categorical_accuracy: 0.8466 - val_loss: 0.8293 - val_categorical_accuracy: 0.6729\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 784s 1s/step - loss: 0.3519 - categorical_accuracy: 0.8649 - val_loss: 0.8774 - val_categorical_accuracy: 0.6692\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 797s 1s/step - loss: 0.3073 - categorical_accuracy: 0.8830 - val_loss: 0.9935 - val_categorical_accuracy: 0.6538\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 790s 1s/step - loss: 0.2721 - categorical_accuracy: 0.8995 - val_loss: 0.9810 - val_categorical_accuracy: 0.6742\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 810s 1s/step - loss: 0.2374 - categorical_accuracy: 0.9139 - val_loss: 1.0678 - val_categorical_accuracy: 0.6556\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 798s 1s/step - loss: 0.2062 - categorical_accuracy: 0.9249 - val_loss: 1.1173 - val_categorical_accuracy: 0.6660\n"
     ]
    }
   ],
   "source": [
    "print(\"TRAINING FOR MODEL7\")\n",
    "train_generator(model7, batch_train_iter, batch_val_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5s3yzfC9ZDlz"
   },
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "-1h29A9uaPWz",
    "outputId": "0341495a-456f-4af3-d20b-bc612ca064ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 90s 15ms/step\n",
      "1.3527190974553427\n",
      "0.649\n"
     ]
    }
   ],
   "source": [
    "#Without drop 0.25\n",
    "print(\"TESTING FOR MODEL1\")\n",
    "loss, accuracy = model1.evaluate(x = test_x_, y = test_y, verbose = 1)\n",
    "\n",
    "print(loss)\n",
    "print(accuracy) # test acc is 64.9%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qEywcGoVkpkw"
   },
   "outputs": [],
   "source": [
    "print(\"TESTING FOR MODEL2\")\n",
    "loss, accuracy = model2.evaluate(x = test_x_, y = test_y, verbose = 1)\n",
    "\n",
    "print(loss)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JFtqPDnKkpqV"
   },
   "outputs": [],
   "source": [
    "print(\"TESTING FOR MODEL3\")\n",
    "loss, accuracy = model3.evaluate(x = test_x_, y = test_y, verbose = 1)\n",
    "\n",
    "print(loss)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING FOR MODEL7\n",
      "6000/6000 [==============================] - 67s 11ms/step\n",
      "1.1489095962842306\n",
      "0.6581666666666667\n"
     ]
    }
   ],
   "source": [
    "print(\"TESTING FOR MODEL7\")\n",
    "loss, accuracy = model7.evaluate(x = test_x_, y = test_y, verbose = 1)\n",
    "\n",
    "print(loss)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of the model\n",
    "\n",
    "\n",
    "#### UniDirectional RNN\n",
    "\n",
    "model6: acc:61.45 (no embd drop, lstm dropout = 0.5, reccr drop = 0.1), approx. training time: 96mins\n",
    "\n",
    "model4: acc:64.03 (embd drop = 0.25, lstm dropout = 0.5, reccr drop = 0.1), approx. training time: 75mins\n",
    "\n",
    "model5: acc:61.75 (embd drop = 0.25, lstm dropout = 0.5, reccr drop = 0.2), approx. training time: 85mins\n",
    "\n",
    "\n",
    "#### BiDirectional RNN\n",
    "\n",
    "model1: acc:61.38 (no embd drop, lstmdrop = 0.5, recdrop = 0.1), approx. training time: 145mins\n",
    "\n",
    "model2: acc:63.93 (embd drop = 0.25, lstmdrop = 0.5, recdrop = 0.1), approx. training time: 145mins\n",
    "\n",
    "model3: acc:63.88 (embd drop = 0.25, lstmdrop = 0.5, recdrop = 0.2), approx. training time: 140mins\n",
    "\n",
    "model7: acc:65.81 (embd drop = 0.25, lstmdrop = 0.5, recdrop = 0.2, merge_mode = 'ave'), approx. training time: 150mins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that in Uni Directional when having dropout for each embedding layer, lastm layer and reccurent dropout we get the highest accuracy during evaluation as overfitting in the training set has been reduced and thus the model is able to predict the unseen with higher accuracy. Also has less training time than the other models as the number of neurons that are less significant are dropped out.\n",
    "\n",
    "In Bi Directional we can see that model7 achieves high accuracy with merge mode as average but takes more time for training. Considering the tradeoff between accuracy and training time we can conclude that the configuration in model2 is best performing.\n",
    "\n",
    "The above reported are the models that give some meaningful change/insight into the performance of the model for small variation in hyper parameters among all the other models that were tried."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment-3.1.1.Document-Level-Sentiment-Analysis.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
